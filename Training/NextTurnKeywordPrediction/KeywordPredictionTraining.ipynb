{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "import os.path\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "import tensorflow_hub as hub\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from Knowledge.ConceptNet import ConceptNet\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from nltk import word_tokenize\n",
    "import networkx as nx\n",
    "import copy\n",
    "from torch_geometric.utils import add_self_loops\n",
    "from torch_geometric.nn import MessagePassing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## BERT Context Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ConceptNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ConceptNet Constructing] Using GLoVe\n",
      "[ConceptNet Constructing] Load ConceptNet from file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2206782/2206782 [00:12<00:00, 176737.54it/s]\n"
     ]
    }
   ],
   "source": [
    "conceptnet = ConceptNet('../../Knowledge/Data/', numberbatch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Check CUDA Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate Filtering Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def candidate_nodes(graph, start_concepts, hops=2):\n",
    "    result = []\n",
    "    for start_concept in start_concepts:\n",
    "        if graph.has_node(start_concept):\n",
    "            result.append(start_concept)\n",
    "    q = copy.deepcopy(result)\n",
    "\n",
    "    for i in range(hops):\n",
    "        temp = []\n",
    "        while len(q) != 0:\n",
    "            head = q.pop(0)\n",
    "            adj = list(graph.neighbors(head))\n",
    "            result.extend(adj)\n",
    "            temp.extend(adj)\n",
    "        q = list(set(temp))\n",
    "    return list(set(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'student' in candidate_nodes(global_graph, ['type', 'cuisine'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BERT = False\n",
    "if BERT:\n",
    "    BERT_model_name = 'bert-base-uncased'\n",
    "    BERT_tokenizer = BertTokenizer.from_pretrained(BERT_model_name)\n",
    "    BERT_model = BertModel.from_pretrained(BERT_model_name)\n",
    "    BERT_model.requires_grad_(False)\n",
    "\n",
    "    def bert_context(context):\n",
    "        context = \"[CLS] \" + context\n",
    "\n",
    "        # Tokenize and encode the context\n",
    "        context_tokens = BERT_tokenizer.encode(context, add_special_tokens=True)\n",
    "        input_ids = torch.tensor(context_tokens).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        # Pass through BERT model\n",
    "        with torch.no_grad():\n",
    "            outputs = BERT_model(input_ids)\n",
    "        context_representation = outputs.last_hidden_state[:, 0, :]\n",
    "        return context_representation.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        y = self.conv1(x, edge_index)\n",
    "        y = F.relu(y)\n",
    "        y = self.conv2(y, edge_index)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class KETransEGCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(KETransEGCNConv, self).__init__(aggr='mean', flow=\"target_to_source\")  # Disable built-in aggregation\n",
    "\n",
    "        self.Ws = nn.Linear(in_channels, out_channels).cuda()\n",
    "        self.Wn = nn.Linear(in_channels, out_channels).cuda()\n",
    "        self.Wr = nn.Linear(in_channels, out_channels).cuda()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_type):\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        edge_type = torch.cat((edge_type.cuda(), torch.zeros(x.size(0), edge_type.size(1)).cuda()), 0)\n",
    "        return self.propagate(edge_index, x=x, edge_type=edge_type)\n",
    "\n",
    "    def message(self, x_i, x_j, edge_type):\n",
    "        head = x_i.requires_grad_(True).cuda()\n",
    "        tail = x_j.requires_grad_(True).cuda()\n",
    "        rel = edge_type.requires_grad_(True).cuda()\n",
    "\n",
    "        dist = -(torch.norm(head + rel - tail, p=2, dim=1)**2)\n",
    "        gradients_head = torch.autograd.grad(dist, head, torch.ones_like(dist).cuda(), retain_graph=True)[0]\n",
    "\n",
    "        return self.Wn(gradients_head)\n",
    "\n",
    "    def update(self, aggr_out, x, edge_type):\n",
    "        new_node_embedding = self.Ws(x.cuda()) + aggr_out.cuda()\n",
    "        new_edge_type = self.Wr(edge_type.cuda())\n",
    "        return new_node_embedding, new_edge_type[:new_edge_type.size(0)-new_node_embedding.size(0)]\n",
    "\n",
    "class KETransEGCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(KETransEGCN, self).__init__()  # Disable built-in aggregation\n",
    "\n",
    "        self.conv1 = KETransEGCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = KETransEGCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_type):\n",
    "        x, edge_type = self.conv1(x, edge_index, edge_type)\n",
    "        x = F.relu(x)\n",
    "        x, _ = self.conv2(x, edge_index, edge_type)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class TransEGCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(TransEGCNConv, self).__init__(aggr='mean', flow=\"target_to_source\")  # Disable built-in aggregation\n",
    "\n",
    "        self.Ws = nn.Linear(in_channels, out_channels).cuda()\n",
    "        self.Wn = nn.Linear(in_channels, out_channels).cuda()\n",
    "        self.Wr = nn.Linear(in_channels, out_channels).cuda()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_type):\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        edge_type = torch.cat((edge_type.cuda(), torch.zeros(x.size(0), edge_type.size(1)).cuda()), 0)\n",
    "        return self.propagate(edge_index, x=x, edge_type=edge_type)\n",
    "\n",
    "    def message(self, x_j, edge_type):\n",
    "        return self.Wn(x_j - edge_type)\n",
    "\n",
    "    def update(self, aggr_out, x, edge_type):\n",
    "        new_node_embedding = self.Ws(x.cuda()) + aggr_out.cuda()\n",
    "        new_edge_type = self.Wr(edge_type.cuda())\n",
    "        return new_node_embedding, new_edge_type[:new_edge_type.size(0)-new_node_embedding.size(0)]\n",
    "\n",
    "\n",
    "class TransEGCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(TransEGCN, self).__init__()  # Disable built-in aggregation\n",
    "\n",
    "        self.conv1 = TransEGCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = TransEGCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_type):\n",
    "        x, edge_type = self.conv1(x, edge_index, edge_type)\n",
    "        x = F.relu(x)\n",
    "        x, _ = self.conv2(x, edge_index, edge_type)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(input_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        y = self.conv1(x, edge_index)\n",
    "        y = F.relu(y)\n",
    "        y = self.conv2(y, edge_index)\n",
    "        y = F.relu(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword Prediction Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from Knowledge.ConceptBlacklist import blacklist\n",
    "\n",
    "\n",
    "class KeywordPredictionDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 conceptnet,\n",
    "                 device='cuda:0',\n",
    "                 preprocessed_dataset = None,\n",
    "                 slice=[0, 1000]):\n",
    "        self.dataset = None\n",
    "        self.device = device\n",
    "\n",
    "        self.edge_embeddings = {}\n",
    "        self.pst = PorterStemmer()\n",
    "\n",
    "        self.conceptnet = conceptnet\n",
    "        if preprocessed_dataset is None:\n",
    "            self.load_data('../Data/tgconv_train.json', slice)\n",
    "        else:\n",
    "            self.dataset = preprocessed_dataset\n",
    "\n",
    "\n",
    "    def load_data(self, path, slice):\n",
    "        f = open(path)\n",
    "        lines = f.readlines()\n",
    "        lines = lines[slice[0]:slice[1]]\n",
    "\n",
    "        dataset = []\n",
    "\n",
    "        pbar = tqdm(lines)\n",
    "        for line in pbar:\n",
    "            data = eval(line.strip())\n",
    "            dialogs = data['dialog']\n",
    "            concepts = data['concepts']\n",
    "            entity_path = data['entity_path']\n",
    "            start_concepts = concepts[0]\n",
    "            target = data['entity_path'][-1]\n",
    "\n",
    "            if target in blacklist:\n",
    "                continue\n",
    "\n",
    "            # bidirectional reasoning\n",
    "            global_graph = self.conceptnet.bidirectional_reasoning(start_concepts, target, K=10, hops=3)\n",
    "            for start_concept in start_concepts:\n",
    "                global_graph = nx.compose(global_graph, self.conceptnet.bidirectional_reasoning([target], start_concept, K=10, hops=3))\n",
    "            global_graph_nodes = global_graph.nodes\n",
    "            global_node_mapping = dict(zip(list(global_graph_nodes), range(len(global_graph_nodes))))\n",
    "            G_global = from_networkx(global_graph).to(self.device)\n",
    "\n",
    "            target_neighbours = list(global_graph.neighbors(target))\n",
    "            target_graph = nx.Graph()\n",
    "            target_graph.add_node(target, x=conceptnet.concept_embedding.stoi[target])\n",
    "            for target_neighbour in target_neighbours:\n",
    "                target_graph.add_node(target_neighbour, x=conceptnet.concept_embedding.stoi[target_neighbour])\n",
    "                target_graph.add_edge(target, target_neighbour)\n",
    "            G_target = from_networkx(target_graph).to(self.device)\n",
    "\n",
    "            # dialog_datas = []\n",
    "            # for idx in range(1, len(dialogs) - 1):\n",
    "            if len(dialogs)  < 3:\n",
    "                continue\n",
    "\n",
    "            idx = random.randint(1, len(dialogs) - 2)\n",
    "            contexts = dialogs[:idx]\n",
    "            start_concepts = concepts[idx-1]\n",
    "            predicted_concepts = concepts[idx]\n",
    "            bridge_concepts = concepts[idx - 1]\n",
    "\n",
    "            if len(set(bridge_concepts) & set(global_graph_nodes)) == 0 \\\n",
    "                    or len(set(predicted_concepts) & set(global_graph_nodes)) == 0:\n",
    "                continue\n",
    "\n",
    "            start_indices = [global_node_mapping[node] for node in list(set(concepts[idx-1]) & set(global_graph_nodes))]\n",
    "            predicted_indices = [global_node_mapping[node] for node in list(set(concepts[idx]) & set(global_graph_nodes))]\n",
    "\n",
    "            candidates = candidate_nodes(global_graph, bridge_concepts, hops=2)\n",
    "            candidate_indices = [global_node_mapping[node] for node in candidates]\n",
    "\n",
    "            # label\n",
    "            labels = torch.ones(len(global_graph_nodes), dtype=int) * -1\n",
    "            labels[candidate_indices] = 0\n",
    "            labels[predicted_indices] = 1\n",
    "            labels[start_indices] = 2\n",
    "            labels = labels.to(self.device)\n",
    "\n",
    "            dataset.append(\n",
    "                {\n",
    "                    'G_global': G_global,\n",
    "                    'G_target': G_target,\n",
    "                    'target': target,\n",
    "                    'node_list': list(global_graph.nodes),\n",
    "                    'contexts': contexts,\n",
    "                    'labels': labels\n",
    "                }\n",
    "            )\n",
    "            # if len(dialog_datas) > 0:\n",
    "            #     dataset.append(dialog_datas)\n",
    "        self.dataset = dataset\n",
    "        return dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class KeywordPredictor(nn.Module):\n",
    "    def __init__(self,\n",
    "                 linear_input_dim=300,\n",
    "                 GCN_input_dim=1112,\n",
    "                 GCN_hidden_dim=512,\n",
    "                 GRU_hidden_dim=256,\n",
    "                 embedding_dim=300,\n",
    "                 cross_entropy_weight=[1,1],\n",
    "                 device='cuda:0',\n",
    "                 balanced_loss=False,\n",
    "                 GCN_layer='GCN',\n",
    "                 num_relations=-1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.input_dim = linear_input_dim\n",
    "        self.fc = nn.Sequential()\n",
    "        self.fc.add_module('linear1', nn.Linear(300, 512))\n",
    "        self.fc.add_module('relu1', nn.LeakyReLU())\n",
    "        self.fc.add_module('linear2', nn.Linear(512, 128))\n",
    "        self.fc.add_module('relu2', nn.LeakyReLU())\n",
    "        self.fc.add_module('linear3', nn.Linear(128, 1))\n",
    "        self.fc = self.fc.to(self.device)\n",
    "\n",
    "        self.loss_func = nn.BCEWithLogitsLoss(weight=torch.FloatTensor(cross_entropy_weight).to(device))\n",
    "\n",
    "        self.GCN_input = GCN_input_dim\n",
    "        self.GCN_output = embedding_dim\n",
    "        self.GCN_hidden = GCN_hidden_dim\n",
    "        self.GCN = GCN(self.GCN_input, self.GCN_hidden, 300).to(device)\n",
    "\n",
    "        self.GRU_input_dim = embedding_dim\n",
    "        self.GRU_hidden_dim = GRU_hidden_dim\n",
    "        self.GRU_layer_size = 1\n",
    "        self.GRU = nn.GRU(self.GRU_input_dim,\n",
    "                          self.GRU_hidden_dim,\n",
    "                          self.GRU_layer_size,\n",
    "                          bidirectional=True).to(self.device)\n",
    "\n",
    "        self.glove_embedding = nn.Embedding.from_pretrained(conceptnet.concept_embedding.vectors).to(device).requires_grad_(False)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.GCN(x, edge_index)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def predict(self, x, edge_index):\n",
    "        with torch.no_grad():\n",
    "            y = self.forward(x, edge_index)\n",
    "        return y\n",
    "\n",
    "    def initialize(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_uniform(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def collate_fn(_batch, _keyword_predictor, _GLoVE, _device='cuda:0', total_dataset=False):\n",
    "    _states = []\n",
    "    _labels = []\n",
    "    _node_list = []\n",
    "    _edge_index = []\n",
    "    for __batch in _batch:\n",
    "        if total_dataset:\n",
    "            __batch = random.choice(__batch)\n",
    "        _global_graph_features = _GLoVE(__batch['G_global'].x)\n",
    "        _global_graph_edge_index = __batch['G_global'].edge_index\n",
    "\n",
    "        _target_encoded = conceptnet.concept_embedding[__batch['target']].repeat(__batch['G_global'].num_nodes, 1).cuda()\n",
    "\n",
    "        _context_tokens = []\n",
    "        for _context in __batch['contexts']:\n",
    "            _context_tokens.extend(word_tokenize(_context))\n",
    "        _context_ids = []\n",
    "        for _concept in _context_tokens:\n",
    "            if _concept in conceptnet.concept_embedding.stoi:\n",
    "                _context_ids.append(conceptnet.concept_embedding[_concept])\n",
    "        _, _hn = _keyword_predictor.GRU(torch.stack(_context_ids).to(device))\n",
    "        _hn = _hn.reshape(-1)\n",
    "        _context = _hn.repeat(__batch['G_global'].num_nodes, 1).clone().detach().requires_grad_(True)\n",
    "\n",
    "        __labels = __batch['labels'].clone().detach().cuda()\n",
    "        __labels[__labels == 1] = 0\n",
    "        __labels[__labels == 2] = 2\n",
    "        __labels = __labels.unsqueeze(1)\n",
    "\n",
    "        _state = torch.cat((_global_graph_features, _target_encoded, _context, __labels), 1)\n",
    "        _states.append(_state)\n",
    "\n",
    "        __batch['labels'][__batch['labels'] == 2] = -1\n",
    "\n",
    "        _labels.append(__batch['labels'])\n",
    "        _node_list.append(__batch['node_list'])\n",
    "        _edge_index.append(_global_graph_edge_index)\n",
    "    return {\n",
    "        'state': _states,\n",
    "        'node_lists': _node_list,\n",
    "        'labels': _labels,\n",
    "        'edge_index': _edge_index\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 30\n",
    "lr = 1e-06\n",
    "decay_rate = 0.85\n",
    "lr_decay_rate = 0.85\n",
    "class_balanced = False\n",
    "input_dim = 512 + 300 + 300\n",
    "weight_decay_rate = 1e-5\n",
    "cross_entropy_weight = [1, 1, 1]\n",
    "context_encoder = 'glove'\n",
    "method = 'GRU'\n",
    "TransE = False\n",
    "GCN_layer = 'GCN'\n",
    "num_relations = 626976\n",
    "\n",
    "device = 'cuda:0'\n",
    "save_name = '{}_batch_{}_lr_{:.0e}_lr_decay_{:.0e}_sigmoid'.format('focal_loss' if class_balanced else 'cross_entropy',\n",
    "                                                            batch_size, lr,lr_decay_rate,cross_entropy_weight[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('./model/{}'.format(save_name)):\n",
    "    os.makedirs('./model/{}'.format(save_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"\n",
    "universal_sentence_encoder = hub.load(model_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2979]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "dialog = [\"I printed out a magic the gathering card and completed it. I was so proud of myself.\",\n",
    "\"I'm proud of you too! That's a lot of hard work and dedication.\",\n",
    "\"Thank you! It took dedication and hard work, but it was worth it in the end.\",\n",
    "\"How long did it take you to complete it?\"]\n",
    "\n",
    "encoded = universal_sentence_encoder(dialog)\n",
    "encoded = torch.tensor(encoded.numpy(), dtype=torch.float)\n",
    "encoded\n",
    "util.cos_sim(encoded[0], encoded[1])\n",
    "util.cos_sim(encoded[1], encoded[2])\n",
    "util.cos_sim(encoded[2], encoded[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\89748\\AppData\\Local\\Temp\\ipykernel_28688\\2528414102.py:77: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
      "  nn.init.kaiming_uniform(m.weight)\n"
     ]
    }
   ],
   "source": [
    "keyword_predictor = KeywordPredictor(linear_input_dim=300,\n",
    "                                     balanced_loss=class_balanced,\n",
    "                                     cross_entropy_weight=[5],\n",
    "                                     GCN_layer= GCN_layer,\n",
    "                                     GCN_input_dim=1113,\n",
    "                                     num_relations=0)\n",
    "keyword_predictor.initialize()\n",
    "\n",
    "load_model = False\n",
    "start_epoch = 5\n",
    "load_model_path = './model/{}/model_epoch{}.pth'.format(save_name, start_epoch)\n",
    "if load_model:\n",
    "    # state_dict = torch.load(load_model_path)\n",
    "    state_dict = torch.load('./model/BCE/model_epoch10.pth')\n",
    "    keyword_predictor.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeywordPredictor(\n",
       "  (fc): Sequential(\n",
       "    (linear1): Linear(in_features=300, out_features=512, bias=True)\n",
       "    (relu1): LeakyReLU(negative_slope=0.01)\n",
       "    (linear2): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (relu2): LeakyReLU(negative_slope=0.01)\n",
       "    (linear3): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       "  (loss_func): BCEWithLogitsLoss()\n",
       "  (GCN): GCN(\n",
       "    (conv1): GCNConv(1113, 512)\n",
       "    (conv2): GCNConv(512, 300)\n",
       "  )\n",
       "  (GRU): GRU(300, 256, bidirectional=True)\n",
       "  (glove_embedding): Embedding(400000, 300)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "glove_embedding = keyword_predictor.glove_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [02:21<00:00, 12.84s/it]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import RandomSampler\n",
    "\n",
    "dataset = []\n",
    "preprocessed_dataset = []\n",
    "for i in tqdm(range(11)):\n",
    "    data = pickle.load(open('../Data/random/random_selected_train_{}.txt'.format(i), 'rb'))\n",
    "    preprocessed_dataset.extend(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 9963/10329 [00:03<00:00, 3280.91it/s]\n",
      "100%|█████████▉| 9950/9963 [00:01<00:00, 5253.58it/s]\n",
      "100%|██████████| 9950/9950 [00:01<00:00, 5220.31it/s]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    for i, preprocessed_data in enumerate(tqdm(preprocessed_dataset)):\n",
    "        if (torch.sum((preprocessed_data['labels'] == 1).float())) == 0:\n",
    "            preprocessed_dataset.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412 7070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['study', 'learning', 'school', 'human', 'love'], 0.7556261209846751)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Knowledge.ConceptBlacklist import blacklist\n",
    "\n",
    "print(len(set(preprocessed_dataset[0]['node_list']) & set(blacklist)), len(preprocessed_dataset[0]['node_list']))\n",
    "set(preprocessed_dataset[0]['node_list']) & set(blacklist)\n",
    "\n",
    "conceptnet.shortest_path('study', 'love')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i also remodel homes when i am not out bow hunting .\n",
      "tensor(139., device='cuda:0')\n",
      "tensor(2., device='cuda:0')\n",
      "tensor(4., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed_dataset[0]['contexts'][0])\n",
    "print(sum((preprocessed_dataset[0]['labels'] == 0).float()))\n",
    "print(sum((preprocessed_dataset[0]['labels'] == 1).float()))\n",
    "print(sum((preprocessed_dataset[0]['labels'] == 2).float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preprocessed_validation_dataset = pickle.load(open('../Data/random/random_selected_valid.txt', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 695/730 [00:00<00:00, 3959.79it/s]\n",
      "100%|█████████▉| 694/695 [00:00<00:00, 5484.58it/s]\n",
      "100%|██████████| 694/694 [00:00<00:00, 5710.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    for i, preprocessed_validation_data in enumerate(tqdm(preprocessed_validation_dataset)):\n",
    "        if (torch.sum((preprocessed_validation_data['labels'] == 1).float())) == 0:\n",
    "            preprocessed_validation_dataset.pop(i)\n",
    "print(len(preprocessed_validation_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Length: 9950\n",
      "Valid Dataset Length: 694\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.sampler import RandomSampler\n",
    "\n",
    "train_dataset = KeywordPredictionDataset(conceptnet, preprocessed_dataset=preprocessed_dataset)\n",
    "valid_dataset = KeywordPredictionDataset(conceptnet, preprocessed_dataset=preprocessed_validation_dataset)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler = RandomSampler(train_dataset),\n",
    "                                  collate_fn=lambda x: collate_fn(x, keyword_predictor, glove_embedding, total_dataset=False))\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, sampler = RandomSampler(valid_dataset),\n",
    "                              collate_fn=lambda x: collate_fn(x, keyword_predictor, glove_embedding, total_dataset=False))\n",
    "\n",
    "print(\"Train Dataset Length: {}\".format(len(preprocessed_dataset)))\n",
    "print(\"Valid Dataset Length: {}\".format(len(preprocessed_validation_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9950/9950 [00:03<00:00, 2521.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 678212, 1: 23078, -1: 40600804}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "labels_count = {0: 0, 1: 0, -1: 0}\n",
    "for t in tqdm(train_dataset):\n",
    "    label = t['labels']\n",
    "    counter = Counter(label.cpu().numpy())\n",
    "    labels_count[-1] = labels_count[-1] + counter[-1]\n",
    "    labels_count[0] = labels_count[0] + counter[0]\n",
    "    labels_count[1] = labels_count[1] + counter[1]\n",
    "labels_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x173234563a0>,\n",
       "  <matplotlib.axis.XTick at 0x17323456100>],\n",
       " [Text(0, 0, '0'), Text(1, 0, '1')])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar([0,1],[labels_count[0], labels_count[1]], width=[0.3,0.3])\n",
    "plt.xticks([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "seed = 131\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 0, step: 2487] loss=0.8169081807136536: 100%|██████████| 2488/2488 [02:47<00:00, 14.90it/s]\n",
      "100%|██████████| 174/174 [00:08<00:00, 19.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.25392136681762045\n",
      "top 10 acc: 0.3858412240977084\n",
      "top 15 acc: 0.4731130780842598\n",
      "top 20 acc: 0.5394675449430497\n",
      "top 25 acc: 0.5949910800054896\n",
      "top 30 acc: 0.6424454508028\n",
      "top 35 acc: 0.6841361328393034\n",
      "epoch: 0, train loss: 1.8377561277658994\n",
      "epoch: 0, valid loss: 1.6335724592208862\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 1, step: 2487] loss=2.9311604499816895: 100%|██████████| 2488/2488 [02:44<00:00, 15.14it/s]\n",
      "100%|██████████| 174/174 [00:08<00:00, 21.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.26016536297516135\n",
      "top 10 acc: 0.3886029916289285\n",
      "top 15 acc: 0.47075957184026346\n",
      "top 20 acc: 0.5406683134348841\n",
      "top 25 acc: 0.5965520790448745\n",
      "top 30 acc: 0.6468642788527516\n",
      "top 35 acc: 0.6835357485933856\n",
      "epoch: 1, train loss: 1.528412752332603\n",
      "epoch: 1, valid loss: 1.4638350009918213\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 2, step: 2487] loss=0.5253952145576477: 100%|██████████| 2488/2488 [02:38<00:00, 15.72it/s]\n",
      "100%|██████████| 174/174 [00:08<00:00, 21.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.25757170303279814\n",
      "top 10 acc: 0.3902120214079868\n",
      "top 15 acc: 0.4712398792369975\n",
      "top 20 acc: 0.5395876217922329\n",
      "top 25 acc: 0.5987614930698508\n",
      "top 30 acc: 0.6445828187182657\n",
      "top 35 acc: 0.6817345958556336\n",
      "epoch: 2, train loss: 1.4354615827896586\n",
      "epoch: 2, valid loss: 1.4172108173370361\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 3, step: 2487] loss=0.40814274549484253: 100%|██████████| 2488/2488 [02:36<00:00, 15.85it/s]\n",
      "100%|██████████| 174/174 [00:08<00:00, 21.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.25901262522299995\n",
      "top 10 acc: 0.3899718677096201\n",
      "top 15 acc: 0.4729209551255661\n",
      "top 20 acc: 0.5397076986414162\n",
      "top 25 acc: 0.5993618773157677\n",
      "top 30 acc: 0.6453032798133662\n",
      "top 35 acc: 0.6821668725126938\n",
      "epoch: 3, train loss: 1.411088368253501\n",
      "epoch: 3, valid loss: 1.4050191640853882\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 4, step: 2487] loss=0.26139920949935913: 100%|██████████| 2488/2488 [02:37<00:00, 15.79it/s]\n",
      "100%|██████████| 174/174 [00:08<00:00, 20.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.25901262522299995\n",
      "top 10 acc: 0.3904041443666803\n",
      "top 15 acc: 0.4722004940304651\n",
      "top 20 acc: 0.5397076986414161\n",
      "top 25 acc: 0.5982811856731165\n",
      "top 30 acc: 0.6460717716481404\n",
      "top 35 acc: 0.682166872512694\n",
      "epoch: 4, train loss: 1.4042924644000276\n",
      "epoch: 4, valid loss: 1.4013603925704956\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 5, step: 2487] loss=0.47890782356262207: 100%|██████████| 2488/2488 [02:37<00:00, 15.82it/s]\n",
      "100%|██████████| 174/174 [00:07<00:00, 22.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.25997324001646765\n",
      "top 10 acc: 0.3911726362014547\n",
      "top 15 acc: 0.47248867846850573\n",
      "top 20 acc: 0.5392273912446823\n",
      "top 25 acc: 0.5982811856731165\n",
      "top 30 acc: 0.6477528475367093\n",
      "top 35 acc: 0.6830794565664883\n",
      "epoch: 5, train loss: 1.40148644875196\n",
      "epoch: 5, valid loss: 1.3994446992874146\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 6, step: 2487] loss=0.44981062412261963: 100%|██████████| 2488/2488 [02:36<00:00, 15.87it/s]\n",
      "100%|██████████| 174/174 [00:07<00:00, 21.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.26009331686565124\n",
      "top 10 acc: 0.39117263620145465\n",
      "top 15 acc: 0.4706154796212435\n",
      "top 20 acc: 0.5392273912446827\n",
      "top 25 acc: 0.5995299849046247\n",
      "top 30 acc: 0.648953616028544\n",
      "top 35 acc: 0.6826471799094279\n",
      "epoch: 6, train loss: 1.3996405827175\n",
      "epoch: 6, valid loss: 1.3981759548187256\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 7, step: 2487] loss=0.5029411315917969: 100%|██████████| 2488/2488 [02:38<00:00, 15.72it/s]\n",
      "100%|██████████| 174/174 [00:08<00:00, 21.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.26117400850830264\n",
      "top 10 acc: 0.3910525593522712\n",
      "top 15 acc: 0.47061547962124317\n",
      "top 20 acc: 0.539227391244682\n",
      "top 25 acc: 0.6016913681899274\n",
      "top 30 acc: 0.648953616028544\n",
      "top 35 acc: 0.6840881020996294\n",
      "epoch: 7, train loss: 1.3980598413412402\n",
      "epoch: 7, valid loss: 1.3970606327056885\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 8, step: 2487] loss=0.5701156258583069: 100%|██████████| 2488/2488 [02:38<00:00, 15.74it/s]\n",
      "100%|██████████| 174/174 [00:08<00:00, 21.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.26261493069850417\n",
      "top 10 acc: 0.39249348154247315\n",
      "top 15 acc: 0.46917455743104164\n",
      "top 20 acc: 0.5392273912446823\n",
      "top 25 acc: 0.603492520927679\n",
      "top 30 acc: 0.6496260463839714\n",
      "top 35 acc: 0.6873301770275833\n",
      "epoch: 8, train loss: 1.3965963659466654\n",
      "epoch: 8, valid loss: 1.3960341215133667\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 9, step: 2487] loss=1.1008374691009521: 100%|██████████| 2488/2488 [02:39<00:00, 15.58it/s] \n",
      "100%|██████████| 174/174 [00:07<00:00, 21.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.2640558528887059\n",
      "top 10 acc: 0.3921332509949225\n",
      "top 15 acc: 0.4691745574310417\n",
      "top 20 acc: 0.5395155756827232\n",
      "top 25 acc: 0.6034925209276798\n",
      "top 30 acc: 0.6496260463839717\n",
      "top 35 acc: 0.6873301770275836\n",
      "epoch: 9, train loss: 1.3951637252230928\n",
      "epoch: 9, valid loss: 1.3950504064559937\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 10, step: 2487] loss=0.6990329027175903: 100%|██████████| 2488/2488 [02:36<00:00, 15.87it/s]\n",
      "100%|██████████| 174/174 [00:09<00:00, 18.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.2643440373267465\n",
      "top 10 acc: 0.39285371209002334\n",
      "top 15 acc: 0.4691745574310417\n",
      "top 20 acc: 0.5395155756827227\n",
      "top 25 acc: 0.6037807053657198\n",
      "top 30 acc: 0.6496260463839716\n",
      "top 35 acc: 0.6882907918210512\n",
      "epoch: 10, train loss: 1.3937759054794763\n",
      "epoch: 10, valid loss: 1.3940842151641846\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 11, step: 2487] loss=1.7997716665267944: 100%|██████████| 2488/2488 [02:39<00:00, 15.56it/s]\n",
      "100%|██████████| 174/174 [00:08<00:00, 21.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.26458419102511327\n",
      "top 10 acc: 0.39458281871826545\n",
      "top 15 acc: 0.4691745574310418\n",
      "top 20 acc: 0.539995883079457\n",
      "top 25 acc: 0.6037807053657201\n",
      "top 30 acc: 0.6481851241937702\n",
      "top 35 acc: 0.6885309455194185\n",
      "epoch: 11, train loss: 1.3924300762378519\n",
      "epoch: 11, valid loss: 1.3931607007980347\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 12, step: 2487] loss=2.0024447441101074: 100%|██████████| 2488/2488 [02:39<00:00, 15.56it/s]\n",
      "100%|██████████| 174/174 [00:08<00:00, 21.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.263503499382462\n",
      "top 10 acc: 0.3945828187182656\n",
      "top 15 acc: 0.4695347879785923\n",
      "top 20 acc: 0.5404761904761907\n",
      "top 25 acc: 0.6037807053657198\n",
      "top 30 acc: 0.649265815836421\n",
      "top 35 acc: 0.6894435295732123\n",
      "epoch: 12, train loss: 1.391107434221211\n",
      "epoch: 12, valid loss: 1.3922529220581055\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 13, step: 2487] loss=0.2852536737918854: 100%|██████████| 2488/2488 [02:56<00:00, 14.13it/s]\n",
      "100%|██████████| 174/174 [00:22<00:00,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.26302319198572804\n",
      "top 10 acc: 0.39638397145601756\n",
      "top 15 acc: 0.469534787978592\n",
      "top 20 acc: 0.5408364210237407\n",
      "top 25 acc: 0.6030602442706189\n",
      "top 30 acc: 0.6507067380266229\n",
      "top 35 acc: 0.6899238369699466\n",
      "epoch: 13, train loss: 1.3898165139139083\n",
      "epoch: 13, valid loss: 1.3913859128952026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 14, step: 2487] loss=0.22824439406394958: 100%|██████████| 2488/2488 [04:07<00:00, 10.05it/s]\n",
      "100%|██████████| 174/174 [00:08<00:00, 19.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.26326334568409493\n",
      "top 10 acc: 0.3963839714560176\n",
      "top 15 acc: 0.4698950185261425\n",
      "top 20 acc: 0.5408364210237412\n",
      "top 25 acc: 0.6041409359132706\n",
      "top 30 acc: 0.650706738026623\n",
      "top 35 acc: 0.6913647591601485\n",
      "epoch: 14, train loss: 1.388569992754333\n",
      "epoch: 14, valid loss: 1.3905304670333862\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 15, step: 2487] loss=0.64771568775177: 100%|██████████| 2488/2488 [03:48<00:00, 10.86it/s]   \n",
      "100%|██████████| 174/174 [00:14<00:00, 12.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.26326334568409504\n",
      "top 10 acc: 0.39739261698915856\n",
      "top 15 acc: 0.46845409633594054\n",
      "top 20 acc: 0.5449190338959791\n",
      "top 25 acc: 0.6037807053657196\n",
      "top 30 acc: 0.6507067380266229\n",
      "top 35 acc: 0.6918450665568822\n",
      "epoch: 15, train loss: 1.3873518821199415\n",
      "epoch: 15, valid loss: 1.3896749019622803\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 16, step: 2487] loss=0.4617288112640381: 100%|██████████| 2488/2488 [03:14<00:00, 12.81it/s]\n",
      "100%|██████████| 174/174 [00:08<00:00, 21.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.2615822697955264\n",
      "top 10 acc: 0.3971524632907919\n",
      "top 15 acc: 0.4689344037326744\n",
      "top 20 acc: 0.5449190338959787\n",
      "top 25 acc: 0.6042610127624538\n",
      "top 30 acc: 0.6526279676135588\n",
      "top 35 acc: 0.6918450665568825\n",
      "epoch: 16, train loss: 1.3861593737048352\n",
      "epoch: 16, valid loss: 1.388878345489502\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 17, step: 2487] loss=1.0603907108306885: 100%|██████████| 2488/2488 [03:20<00:00, 12.38it/s]\n",
      "100%|██████████| 174/174 [00:13<00:00, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.2615822697955263\n",
      "top 10 acc: 0.39715246329079207\n",
      "top 15 acc: 0.46893440373267475\n",
      "top 20 acc: 0.5455674488815699\n",
      "top 25 acc: 0.6047413201591876\n",
      "top 30 acc: 0.6531082750102921\n",
      "top 35 acc: 0.6929257581995332\n",
      "epoch: 17, train loss: 1.3849932288217965\n",
      "epoch: 17, valid loss: 1.3880808353424072\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 18, step: 2487] loss=0.35764437913894653: 100%|██████████| 2488/2488 [03:42<00:00, 11.16it/s]\n",
      "100%|██████████| 174/174 [00:08<00:00, 21.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.2608618087004257\n",
      "top 10 acc: 0.397152463290792\n",
      "top 15 acc: 0.4718162481130781\n",
      "top 20 acc: 0.54556744888157\n",
      "top 25 acc: 0.6050295045972282\n",
      "top 30 acc: 0.6550295045972282\n",
      "top 35 acc: 0.6941265266913682\n",
      "epoch: 18, train loss: 1.3838518422899522\n",
      "epoch: 18, valid loss: 1.3873035907745361\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 19, step: 2487] loss=0.42715203762054443: 100%|██████████| 2488/2488 [02:25<00:00, 17.11it/s]\n",
      "100%|██████████| 174/174 [00:07<00:00, 22.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.2608618087004255\n",
      "top 10 acc: 0.3971524632907922\n",
      "top 15 acc: 0.47325717030328\n",
      "top 20 acc: 0.5449670646356525\n",
      "top 25 acc: 0.605797996432002\n",
      "top 30 acc: 0.6555098119939616\n",
      "top 35 acc: 0.6936462192946343\n",
      "epoch: 19, train loss: 1.3827301438334862\n",
      "epoch: 19, valid loss: 1.3865431547164917\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 20, step: 2487] loss=0.41568851470947266: 100%|██████████| 2488/2488 [02:26<00:00, 17.00it/s]\n",
      "100%|██████████| 174/174 [00:07<00:00, 22.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.2608618087004254\n",
      "top 10 acc: 0.397152463290792\n",
      "top 15 acc: 0.473785508439687\n",
      "top 20 acc: 0.5483292164127899\n",
      "top 25 acc: 0.6063983806779196\n",
      "top 30 acc: 0.6555098119939619\n",
      "top 35 acc: 0.6936462192946343\n",
      "epoch: 20, train loss: 1.3816337945760255\n",
      "epoch: 20, valid loss: 1.3857921361923218\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 21, step: 2487] loss=0.3861979842185974: 100%|██████████| 2488/2488 [02:25<00:00, 17.11it/s] \n",
      "100%|██████████| 174/174 [00:07<00:00, 22.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.26086180870042536\n",
      "top 10 acc: 0.3971524632907919\n",
      "top 15 acc: 0.47378550843968736\n",
      "top 20 acc: 0.5497701386029916\n",
      "top 25 acc: 0.6063983806779195\n",
      "top 30 acc: 0.6569507341841635\n",
      "top 35 acc: 0.6938863729930013\n",
      "epoch: 21, train loss: 1.3805581721629936\n",
      "epoch: 21, valid loss: 1.3850791454315186\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 22, step: 2487] loss=0.3494654893875122: 100%|██████████| 2488/2488 [02:27<00:00, 16.90it/s] \n",
      "100%|██████████| 174/174 [00:07<00:00, 22.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.26206257719226017\n",
      "top 10 acc: 0.39715246329079207\n",
      "top 15 acc: 0.4737855084396875\n",
      "top 20 acc: 0.5497701386029921\n",
      "top 25 acc: 0.606878688074654\n",
      "top 30 acc: 0.6569507341841638\n",
      "top 35 acc: 0.6946068340881023\n",
      "epoch: 22, train loss: 1.3795051660712125\n",
      "epoch: 22, valid loss: 1.3843809366226196\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 23, step: 2487] loss=1.064016580581665: 100%|██████████| 2488/2488 [02:27<00:00, 16.83it/s]  \n",
      "100%|██████████| 174/174 [00:07<00:00, 22.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.26206257719226045\n",
      "top 10 acc: 0.3978729243858926\n",
      "top 15 acc: 0.4733772471524634\n",
      "top 20 acc: 0.5502504459997256\n",
      "top 25 acc: 0.6056779195828189\n",
      "top 30 acc: 0.6572389186222041\n",
      "top 35 acc: 0.694606834088102\n",
      "epoch: 23, train loss: 1.3784619899903847\n",
      "epoch: 23, valid loss: 1.383681297302246\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 24, step: 2487] loss=0.60793137550354: 100%|██████████| 2488/2488 [02:26<00:00, 17.03it/s]  \n",
      "100%|██████████| 174/174 [00:07<00:00, 21.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.2620625771922602\n",
      "top 10 acc: 0.39811307808425983\n",
      "top 15 acc: 0.473857554549197\n",
      "top 20 acc: 0.5502504459997255\n",
      "top 25 acc: 0.6061582269795526\n",
      "top 30 acc: 0.656518457527103\n",
      "top 35 acc: 0.6946068340881021\n",
      "epoch: 24, train loss: 1.3774436962374537\n",
      "epoch: 24, valid loss: 1.3829996585845947\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 25, step: 2487] loss=1.346255898475647: 100%|██████████| 2488/2488 [02:26<00:00, 17.01it/s] \n",
      "100%|██████████| 174/174 [00:08<00:00, 21.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.26242280773981075\n",
      "top 10 acc: 0.3994339234252778\n",
      "top 15 acc: 0.4738575545491971\n",
      "top 20 acc: 0.5502504459997256\n",
      "top 25 acc: 0.6061582269795529\n",
      "top 30 acc: 0.6572389186222041\n",
      "top 35 acc: 0.6966481405242216\n",
      "epoch: 25, train loss: 1.376434530715467\n",
      "epoch: 25, valid loss: 1.3823128938674927\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 26, step: 2487] loss=0.6905581951141357: 100%|██████████| 2488/2488 [02:35<00:00, 16.05it/s]\n",
      "100%|██████████| 174/174 [00:07<00:00, 21.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.26170234664470965\n",
      "top 10 acc: 0.3999142308220121\n",
      "top 15 acc: 0.47241663235899534\n",
      "top 20 acc: 0.5513311376423768\n",
      "top 25 acc: 0.606158226979553\n",
      "top 30 acc: 0.6572389186222042\n",
      "top 35 acc: 0.6966481405242215\n",
      "epoch: 26, train loss: 1.3754508059795263\n",
      "epoch: 26, valid loss: 1.3816674947738647\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 27, step: 2487] loss=0.5832237005233765: 100%|██████████| 2488/2488 [02:25<00:00, 17.08it/s]\n",
      "100%|██████████| 174/174 [00:08<00:00, 21.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.260981885549609\n",
      "top 10 acc: 0.39991423082201194\n",
      "top 15 acc: 0.4733772471524632\n",
      "top 20 acc: 0.5522917524358445\n",
      "top 25 acc: 0.6069987649238371\n",
      "top 30 acc: 0.6583196102648555\n",
      "top 35 acc: 0.6973686016193223\n",
      "epoch: 27, train loss: 1.374473033706475\n",
      "epoch: 27, valid loss: 1.3810176849365234\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 28, step: 2487] loss=0.3153427243232727: 100%|██████████| 2488/2488 [02:26<00:00, 16.98it/s]\n",
      "100%|██████████| 174/174 [00:07<00:00, 22.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.26146219294634293\n",
      "top 10 acc: 0.39991423082201183\n",
      "top 15 acc: 0.4743378619459312\n",
      "top 20 acc: 0.5531322903801292\n",
      "top 25 acc: 0.6074790723205709\n",
      "top 30 acc: 0.6583196102648555\n",
      "top 35 acc: 0.6973686016193223\n",
      "epoch: 28, train loss: 1.3734969274407414\n",
      "epoch: 28, valid loss: 1.3803834915161133\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 29, step: 2487] loss=0.3661792278289795: 100%|██████████| 2488/2488 [02:26<00:00, 16.95it/s]\n",
      "100%|██████████| 174/174 [00:07<00:00, 21.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.2614621929463429\n",
      "top 10 acc: 0.39991423082201194\n",
      "top 15 acc: 0.4738575545491971\n",
      "top 20 acc: 0.5538527514752298\n",
      "top 25 acc: 0.6094003019075066\n",
      "top 30 acc: 0.6587999176615894\n",
      "top 35 acc: 0.6973686016193223\n",
      "epoch: 29, train loss: 1.3725659863789748\n",
      "epoch: 29, valid loss: 1.3797463178634644\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 30, step: 2487] loss=0.6683415770530701: 100%|██████████| 2488/2488 [02:24<00:00, 17.18it/s]\n",
      "100%|██████████| 174/174 [00:07<00:00, 22.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.2614621929463429\n",
      "top 10 acc: 0.39991423082201194\n",
      "top 15 acc: 0.47337724715246343\n",
      "top 20 acc: 0.55385275147523\n",
      "top 25 acc: 0.6101207630026073\n",
      "top 30 acc: 0.6587999176615891\n",
      "top 35 acc: 0.6971284479209552\n",
      "epoch: 30, train loss: 1.3716169897215351\n",
      "epoch: 30, valid loss: 1.3791390657424927\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 31, step: 2487] loss=0.8828964233398438: 100%|██████████| 2488/2488 [03:10<00:00, 13.08it/s]\n",
      "100%|██████████| 174/174 [00:13<00:00, 13.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.2621826540414437\n",
      "top 10 acc: 0.39919376972691106\n",
      "top 15 acc: 0.47385755454919715\n",
      "top 20 acc: 0.55421298202278\n",
      "top 25 acc: 0.6106010703993412\n",
      "top 30 acc: 0.6595203787566901\n",
      "top 35 acc: 0.6971284479209553\n",
      "epoch: 31, train loss: 1.3706699397259203\n",
      "epoch: 31, valid loss: 1.3785252571105957\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 32, step: 2487] loss=0.5667901039123535: 100%|██████████| 2488/2488 [03:46<00:00, 10.96it/s]\n",
      "100%|██████████| 174/174 [00:13<00:00, 13.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.2621826540414438\n",
      "top 10 acc: 0.3991937697269109\n",
      "top 15 acc: 0.47385755454919715\n",
      "top 20 acc: 0.5542129820227809\n",
      "top 25 acc: 0.6106010703993417\n",
      "top 30 acc: 0.6595203787566906\n",
      "top 35 acc: 0.6971284479209554\n",
      "epoch: 32, train loss: 1.3697417633805629\n",
      "epoch: 32, valid loss: 1.3778889179229736\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 33, step: 2487] loss=0.6725570559501648: 100%|██████████| 2488/2488 [03:40<00:00, 11.28it/s] \n",
      "100%|██████████| 174/174 [00:13<00:00, 12.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.2617023466447098\n",
      "top 10 acc: 0.39919376972691123\n",
      "top 15 acc: 0.47385755454919726\n",
      "top 20 acc: 0.5542129820227807\n",
      "top 25 acc: 0.6125222999862773\n",
      "top 30 acc: 0.6591601482091397\n",
      "top 35 acc: 0.6978489090160563\n",
      "epoch: 33, train loss: 1.368834455260989\n",
      "epoch: 33, valid loss: 1.3772807121276855\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 34, step: 2487] loss=0.44177865982055664: 100%|██████████| 2488/2488 [03:45<00:00, 11.05it/s]\n",
      "100%|██████████| 174/174 [00:14<00:00, 12.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.2624228077398105\n",
      "top 10 acc: 0.39919376972691106\n",
      "top 15 acc: 0.4736174008508301\n",
      "top 20 acc: 0.5534925209276794\n",
      "top 25 acc: 0.612522299986277\n",
      "top 30 acc: 0.6587999176615892\n",
      "top 35 acc: 0.6985693701111569\n",
      "epoch: 34, train loss: 1.3679183518627833\n",
      "epoch: 34, valid loss: 1.3766926527023315\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 35, step: 2487] loss=0.27291542291641235: 100%|██████████| 2488/2488 [03:44<00:00, 11.07it/s]\n",
      "100%|██████████| 174/174 [00:13<00:00, 13.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.2624228077398108\n",
      "top 10 acc: 0.3991937697269109\n",
      "top 15 acc: 0.47469809249348166\n",
      "top 20 acc: 0.5542129820227804\n",
      "top 25 acc: 0.6128825305338275\n",
      "top 30 acc: 0.6580794565664884\n",
      "top 35 acc: 0.6978489090160562\n",
      "epoch: 35, train loss: 1.3670267399843674\n",
      "epoch: 35, valid loss: 1.3760875463485718\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 36, step: 2487] loss=0.25957268476486206: 100%|██████████| 2488/2488 [03:53<00:00, 10.67it/s]\n",
      "100%|██████████| 174/174 [00:13<00:00, 12.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.26242280773981075\n",
      "top 10 acc: 0.39919376972691106\n",
      "top 15 acc: 0.4746980924934815\n",
      "top 20 acc: 0.5549814738575546\n",
      "top 25 acc: 0.612522299986277\n",
      "top 30 acc: 0.6597605324550572\n",
      "top 35 acc: 0.699049677507891\n",
      "epoch: 36, train loss: 1.3661448143278863\n",
      "epoch: 36, valid loss: 1.3754998445510864\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 37, step: 2487] loss=0.40780746936798096: 100%|██████████| 2488/2488 [03:49<00:00, 10.85it/s]\n",
      "100%|██████████| 174/174 [00:13<00:00, 12.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.2631432688349115\n",
      "top 10 acc: 0.39955400027446175\n",
      "top 15 acc: 0.4746980924934815\n",
      "top 20 acc: 0.5561822423493894\n",
      "top 25 acc: 0.6139632221764788\n",
      "top 30 acc: 0.6597605324550572\n",
      "top 35 acc: 0.699049677507891\n",
      "epoch: 37, train loss: 1.3652704383016017\n",
      "epoch: 37, valid loss: 1.374894142150879\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 38, step: 2487] loss=0.39867860078811646: 100%|██████████| 2488/2488 [03:53<00:00, 10.65it/s]\n",
      "100%|██████████| 174/174 [00:13<00:00, 12.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.26314326883491157\n",
      "top 10 acc: 0.40003430767119513\n",
      "top 15 acc: 0.47541855358858265\n",
      "top 20 acc: 0.5561822423493894\n",
      "top 25 acc: 0.6146836832715797\n",
      "top 30 acc: 0.6604809935501581\n",
      "top 35 acc: 0.6995299849046248\n",
      "epoch: 38, train loss: 1.3643914417175043\n",
      "epoch: 38, valid loss: 1.3743247985839844\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 39, step: 2487] loss=0.32169705629348755: 100%|██████████| 2488/2488 [03:45<00:00, 11.02it/s]\n",
      "100%|██████████| 174/174 [00:13<00:00, 12.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.2633491148620832\n",
      "top 10 acc: 0.4000343076711954\n",
      "top 15 acc: 0.4754185535885825\n",
      "top 20 acc: 0.5565424728969403\n",
      "top 25 acc: 0.6146836832715796\n",
      "top 30 acc: 0.6612014546452586\n",
      "top 35 acc: 0.6995299849046245\n",
      "epoch: 39, train loss: 1.363530845156724\n",
      "epoch: 39, valid loss: 1.3737573623657227\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 40, step: 2487] loss=0.4841763973236084: 100%|██████████| 2488/2488 [03:51<00:00, 10.76it/s]\n",
      "100%|██████████| 174/174 [00:12<00:00, 13.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.2644298065047345\n",
      "top 10 acc: 0.40003430767119547\n",
      "top 15 acc: 0.475778784136133\n",
      "top 20 acc: 0.5576231645395912\n",
      "top 25 acc: 0.6171332509949229\n",
      "top 30 acc: 0.6609132702072186\n",
      "top 35 acc: 0.6995299849046247\n",
      "epoch: 40, train loss: 1.3626832320112316\n",
      "epoch: 40, valid loss: 1.3731831312179565\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 41, step: 2487] loss=0.3641067147254944: 100%|██████████| 2488/2488 [03:57<00:00, 10.49it/s]\n",
      "100%|██████████| 174/174 [00:13<00:00, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.2644298065047344\n",
      "top 10 acc: 0.40099492246466323\n",
      "top 15 acc: 0.475778784136133\n",
      "top 20 acc: 0.5587038561822423\n",
      "top 25 acc: 0.6171332509949226\n",
      "top 30 acc: 0.6630746534925211\n",
      "top 35 acc: 0.7007307533964597\n",
      "epoch: 41, train loss: 1.3618317843202226\n",
      "epoch: 41, valid loss: 1.3726072311401367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 42, step: 2487] loss=0.4787259101867676: 100%|██████████| 2488/2488 [03:50<00:00, 10.79it/s]\n",
      "100%|██████████| 174/174 [00:16<00:00, 10.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.2649101139014684\n",
      "top 10 acc: 0.4009949224646634\n",
      "top 15 acc: 0.47721970632633476\n",
      "top 20 acc: 0.5594243172773432\n",
      "top 25 acc: 0.6185741731851241\n",
      "top 30 acc: 0.6630746534925209\n",
      "top 35 acc: 0.7012110607931934\n",
      "epoch: 42, train loss: 1.3609843386091602\n",
      "epoch: 42, valid loss: 1.3720324039459229\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 43, step: 2487] loss=0.2917596101760864: 100%|██████████| 2488/2488 [03:49<00:00, 10.83it/s] \n",
      "100%|██████████| 174/174 [00:13<00:00, 13.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.26620694387265004\n",
      "top 10 acc: 0.4002744613695622\n",
      "top 15 acc: 0.47721970632633437\n",
      "top 20 acc: 0.5594243172773434\n",
      "top 25 acc: 0.6185741731851243\n",
      "top 30 acc: 0.6641553451351725\n",
      "top 35 acc: 0.7012110607931937\n",
      "epoch: 43, train loss: 1.3601469566680227\n",
      "epoch: 43, valid loss: 1.3714834451675415\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 44, step: 2487] loss=0.9636850357055664: 100%|██████████| 2488/2488 [03:45<00:00, 11.03it/s] \n",
      "100%|██████████| 174/174 [00:13<00:00, 12.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.2654864827775492\n",
      "top 10 acc: 0.40027446136956213\n",
      "top 15 acc: 0.4783003979689855\n",
      "top 20 acc: 0.559424317277343\n",
      "top 25 acc: 0.6192946342802249\n",
      "top 30 acc: 0.6641553451351724\n",
      "top 35 acc: 0.7012110607931937\n",
      "epoch: 44, train loss: 1.3593217428426267\n",
      "epoch: 44, valid loss: 1.3709299564361572\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 45, step: 2487] loss=0.6684865951538086: 100%|██████████| 2488/2488 [03:55<00:00, 10.57it/s] \n",
      "100%|██████████| 174/174 [00:13<00:00, 12.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.2669274049677509\n",
      "top 10 acc: 0.4002744613695622\n",
      "top 15 acc: 0.4787807053657196\n",
      "top 20 acc: 0.560625085769178\n",
      "top 25 acc: 0.6189344037326747\n",
      "top 30 acc: 0.6646356525319062\n",
      "top 35 acc: 0.7012110607931936\n",
      "epoch: 45, train loss: 1.3585064422183482\n",
      "epoch: 45, valid loss: 1.3703930377960205\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 46, step: 2487] loss=0.9924153089523315: 100%|██████████| 2488/2488 [03:50<00:00, 10.80it/s]\n",
      "100%|██████████| 174/174 [00:12<00:00, 13.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.2669274049677509\n",
      "top 10 acc: 0.3997941539728284\n",
      "top 15 acc: 0.47914093591327017\n",
      "top 20 acc: 0.5615857005626457\n",
      "top 25 acc: 0.6189344037326745\n",
      "top 30 acc: 0.6646356525319062\n",
      "top 35 acc: 0.7012110607931934\n",
      "epoch: 46, train loss: 1.3576892045868554\n",
      "epoch: 46, valid loss: 1.3698394298553467\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 47, step: 2487] loss=1.0518006086349487: 100%|██████████| 2488/2488 [03:47<00:00, 10.94it/s]\n",
      "100%|██████████| 174/174 [00:14<00:00, 11.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47541     0]\n",
      " [ 1638     0]]\n",
      "top k acc\n",
      "top 5 acc: 0.2678880197612185\n",
      "top 10 acc: 0.3988335391793607\n",
      "top 15 acc: 0.4791409359132703\n",
      "top 20 acc: 0.5619459311101963\n",
      "top 25 acc: 0.6189344037326747\n",
      "top 30 acc: 0.6651159599286403\n",
      "top 35 acc: 0.7016913681899274\n",
      "epoch: 47, train loss: 1.3568929604275626\n",
      "epoch: 47, valid loss: 1.3692898750305176\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch: 48, step: 2487] loss=1.006584644317627: 100%|██████████| 2488/2488 [04:00<00:00, 10.35it/s] \n",
      " 56%|█████▋    | 98/174 [00:13<00:10,  7.08it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [35], line 95\u001b[0m\n\u001b[0;32m     92\u001b[0m top_k_values \u001b[38;5;241m=\u001b[39m top_k_output\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     94\u001b[0m predicted_words \u001b[38;5;241m=\u001b[39m node_list[top_k_indices\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()]\n\u001b[1;32m---> 95\u001b[0m actual_words \u001b[38;5;241m=\u001b[39m node_list[\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()]\n\u001b[0;32m     97\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(predicted_words) \u001b[38;5;241m&\u001b[39m \u001b[38;5;28mset\u001b[39m(actual_words)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(actual_words)\n\u001b[0;32m     98\u001b[0m acc_list[k]\u001b[38;5;241m.\u001b[39mappend(acc)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(keyword_predictor.parameters(), lr=1e-6)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=lr_decay_rate)\n",
    "\n",
    "batch_losses = []\n",
    "validation_losses_record = []\n",
    "global_step = 0\n",
    "writer = SummaryWriter('./runs/{}'.format(save_name))\n",
    "\n",
    "global_step = 0\n",
    "down_sampling = True\n",
    "\n",
    "for epoch in range(100):\n",
    "    keyword_predictor.train()\n",
    "\n",
    "    pbar = tqdm(train_dataloader)\n",
    "    epoch_average_loss = 0\n",
    "    epoch_batch_loss = []\n",
    "    for step, batch in enumerate(pbar):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        states = batch['state']\n",
    "        labels = batch['labels']\n",
    "        edge_indices = batch['edge_index']\n",
    "        labels = [label.clone().type(torch.LongTensor).cuda() for label in labels]\n",
    "\n",
    "        losses = []\n",
    "        for i in range(len(states)):\n",
    "            label = labels[i]\n",
    "            state = states[i]\n",
    "            edge_index = edge_indices[i]\n",
    "\n",
    "            output = keyword_predictor(state, edge_index).reshape(-1)\n",
    "\n",
    "            masked = (label != -1)\n",
    "            output = output[masked]\n",
    "            label = label[masked]\n",
    "\n",
    "            cross_entropy_loss = keyword_predictor.loss_func(output, label.float())\n",
    "            losses.append(cross_entropy_loss)\n",
    "\n",
    "        loss = sum(losses)\n",
    "        # loss = torch.div(sum(losses), batch_size)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_batch_loss.append(loss.item())\n",
    "        pbar.set_description('[epoch: {}, step: {}] loss={}'.format(epoch, step, loss.item()/batch_size))\n",
    "        writer.add_scalar('loss/batch', loss.item()/batch_size, global_step)\n",
    "        global_step += 1\n",
    "    batch_losses.extend(epoch_batch_loss)\n",
    "\n",
    "    # validation loss\n",
    "    validation_losses = []\n",
    "    acc_list = {5:[], 10: [], 15: [], 20: [], 25: [], 30: [], 35: []}\n",
    "    k_list = [5,10,15,20,25, 30, 35]\n",
    "    all_true_labels = []\n",
    "    all_predicted_labels = []\n",
    "    for batch in tqdm(valid_dataloader):\n",
    "        states = batch['state']\n",
    "        labels = batch['labels']\n",
    "        edge_indices = batch['edge_index']\n",
    "        node_lists = [np.array(node_list) for node_list in batch['node_lists']]\n",
    "        labels = [label.clone().long() for label in labels]\n",
    "\n",
    "        for i in range(len(states)):\n",
    "            output = keyword_predictor.predict(states[i], edge_indices[i]).reshape(-1)\n",
    "            label = labels[i]\n",
    "            masked = (label != -1)\n",
    "            output = output[masked]\n",
    "            label = label[masked]\n",
    "            node_list = node_lists[i][masked.cpu().detach().numpy()]\n",
    "\n",
    "            cross_entropy_loss = keyword_predictor.loss_func(output, label.float())\n",
    "            validation_losses.append(cross_entropy_loss)\n",
    "\n",
    "            predicted_labels = (output > 0.5)\n",
    "            predicted_labels = predicted_labels.float()\n",
    "\n",
    "            all_true_labels.extend(label.cpu().detach().numpy())\n",
    "            all_predicted_labels.extend(predicted_labels.cpu().detach().numpy())\n",
    "\n",
    "            for k in k_list:\n",
    "                top_k_output = torch.topk(output, k=min(k, output.size(0)))\n",
    "                top_k_indices = top_k_output.indices\n",
    "                top_k_values = top_k_output.values\n",
    "\n",
    "                predicted_words = node_list[top_k_indices.cpu().numpy()]\n",
    "                actual_words = node_list[(label==1).cpu().numpy()]\n",
    "\n",
    "                acc = len(set(predicted_words) & set(actual_words)) / len(actual_words)\n",
    "                acc_list[k].append(acc)\n",
    "\n",
    "    print('top k acc')\n",
    "    acc_list_str = {}\n",
    "    for k in k_list:\n",
    "        acc_list_str[str(k)] = acc_list[k]\n",
    "        print('top {} acc: {}'.format(k, sum(acc_list[k])/len(acc_list[k])))\n",
    "\n",
    "    train_average_loss = sum(epoch_batch_loss)/len(epoch_batch_loss)\n",
    "    validation_loss = sum(validation_losses) / len(validation_losses)\n",
    "    validation_losses_record.append(validation_loss)\n",
    "\n",
    "    print('epoch: {}, train loss: {}'.format(epoch, train_average_loss/batch_size))\n",
    "    print('epoch: {}, valid loss: {}'.format(epoch, validation_loss))\n",
    "    print()\n",
    "\n",
    "    writer.add_scalars('loss/epoch', {'train': train_average_loss, 'valid': validation_loss}, epoch)\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        torch.save(keyword_predictor.state_dict(), './model/{}/model_epoch{}.pth'.format(save_name, epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epoch_loss_length = int(len(batch_losses) / epochs)\n",
    "mean_loss = [np.mean(batch_losses[epoch_loss_length*i:epoch_loss_length*(i+1)]) for i in range(epochs)]\n",
    "std_loss = [np.std(batch_losses[epoch_loss_length*i:epoch_loss_length*(i+1)]) for i in range(epochs)]\n",
    "plt.plot(range(1,26), mean_loss[1:26], label='train')\n",
    "plt.plot(range(1,26), [n.cpu().numpy() for n in validation_losses_record][:25],label='valid')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,9))\n",
    "batch_losses = np.array(batch_losses)\n",
    "plt.plot(np.arange(len(batch_losses)), np.array(batch_losses)/batch_size, label='train')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "multi_label_acc_list = []\n",
    "\n",
    "all_true_labels = []\n",
    "all_predicted_labels = []\n",
    "\n",
    "acc_list = {5:[], 10: [], 15: [], 20: [], 25: [], 30: [], 35: []}\n",
    "k_list = [5,10,15,20,25, 30, 35]\n",
    "\n",
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "for batch in tqdm(valid_dataloader):\n",
    "    states = batch['state']\n",
    "    node_lists = [np.array(node_list) for node_list in batch['node_lists']]\n",
    "    labels = batch['labels']\n",
    "\n",
    "    for i in range(len(states)):\n",
    "        output = keyword_predictor.predict(states[i])\n",
    "        node_list = node_lists[i]\n",
    "        label = labels[i]\n",
    "        label_weight = (labels[i] != -1).float()\n",
    "        label_weight = label_weight.reshape(-1, 1)\n",
    "\n",
    "        predicted_labels = []\n",
    "        for threshold in thresholds:\n",
    "            predicted_label = (output > threshold).float()\n",
    "            predicted_label[(label==-1)] = -1\n",
    "            predicted_label = predicted_label.cpu().numpy().tolist()\n",
    "            predicted_labels.append(predicted_label)\n",
    "        label = labels[i].cpu().numpy().tolist()\n",
    "\n",
    "        all_true_labels.extend(label)\n",
    "        all_predicted_labels.append(predicted_labels)\n",
    "\n",
    "        output = output * label_weight\n",
    "\n",
    "        output = output.reshape(-1)\n",
    "        top_k_output = torch.topk(output, k=5)\n",
    "        top_k_indices = top_k_output.indices\n",
    "        top_k_values = top_k_output.values\n",
    "\n",
    "        predicted_words = node_list[top_k_indices.cpu().numpy()]\n",
    "        print(predicted_words)\n",
    "        actual_words = node_list[(labels[i]==1).cpu().numpy()]\n",
    "        print(actual_words)\n",
    "\n",
    "        acc = len(set(predicted_words) & set(actual_words)) / len(actual_words)\n",
    "        acc_list[k].append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predicted_label_dict = {0.1: [], 0.2: [], 0.3: [], 0.4: [], 0.5: [], 0.6: [], 0.7: [], 0.8: [], 0.9: []}\n",
    "for i in range(len(all_predicted_labels)):\n",
    "    for j in range(len(all_predicted_labels[0])):\n",
    "        predicted_label_dict[thresholds[j]].extend(all_predicted_labels[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "for threshold in thresholds:\n",
    "    cm = confusion_matrix(y_true=all_true_labels, y_pred=predicted_label_dict[threshold])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm[1:, 1:], display_labels=[0,1])\n",
    "    disp.plot(cmap = 'Blues')\n",
    "    plt.title('threshold={}'.format(threshold))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for k in k_list:\n",
    "    print('top {} acc: {}'.format(k, sum(acc_list[k])/len(acc_list[k])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
